[2021-07-01 14:26:02,484] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: get_data_patient.get_users 2021-07-01T14:24:03.261240+00:00 [queued]>
[2021-07-01 14:26:02,501] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: get_data_patient.get_users 2021-07-01T14:24:03.261240+00:00 [queued]>
[2021-07-01 14:26:02,501] {taskinstance.py:1067} INFO - 
--------------------------------------------------------------------------------
[2021-07-01 14:26:02,501] {taskinstance.py:1068} INFO - Starting attempt 3 of 3
[2021-07-01 14:26:02,501] {taskinstance.py:1069} INFO - 
--------------------------------------------------------------------------------
[2021-07-01 14:26:02,524] {taskinstance.py:1087} INFO - Executing <Task(PythonOperator): get_users> on 2021-07-01T14:24:03.261240+00:00
[2021-07-01 14:26:02,531] {standard_task_runner.py:52} INFO - Started process 8599 to run task
[2021-07-01 14:26:02,538] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'get_data_patient', 'get_users', '2021-07-01T14:24:03.261240+00:00', '--job-id', '957', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/get_Data_Patient.py', '--cfg-path', '/tmp/tmpvh_a88mq', '--error-file', '/tmp/tmp2fsu7fq7']
[2021-07-01 14:26:02,541] {standard_task_runner.py:77} INFO - Job 957: Subtask get_users
[2021-07-01 14:26:02,655] {logging_mixin.py:104} INFO - Running <TaskInstance: get_data_patient.get_users 2021-07-01T14:24:03.261240+00:00 [running]> on host airflowvm
[2021-07-01 14:26:02,774] {taskinstance.py:1280} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=get_data_patient
AIRFLOW_CTX_TASK_ID=get_users
AIRFLOW_CTX_EXECUTION_DATE=2021-07-01T14:24:03.261240+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2021-07-01T14:24:03.261240+00:00
[2021-07-01 14:26:02,788] {base.py:69} INFO - Using connection to: id: ***_default. Host: localhost, Port: 5432, Schema: , Login: ***, Password: ***, extra: {'cursor': 'realdictcursor'}
[2021-07-01 14:26:02,801] {logging_mixin.py:104} INFO - RealDictRow([('id', 4718), ('uid', '404d86a4-6138-4d86-87ed-5efbc2561cf9'), ('medical_history', {}), ('user_id', '502c3cfb-2b79-4131-ad46-722e2d470a3b'), ('birthdate', datetime.date(1930, 8, 1)), ('sex', 'M'), ('created_at', datetime.datetime(2021, 3, 30, 9, 50, 38, 662702, tzinfo=datetime.timezone.utc)), ('deleted_at', None), ('updated_at', datetime.datetime(2021, 4, 12, 16, 55, 42, 865377, tzinfo=datetime.timezone.utc)), ('is_test', False)])
[2021-07-01 14:26:02,802] {python.py:151} INFO - Done. Returned value was: {'id': 4718, 'uid': '404d86a4-6138-4d86-87ed-5efbc2561cf9', 'medical_history': {}, 'user_id': '502c3cfb-2b79-4131-ad46-722e2d470a3b', 'birthdate': datetime.date(1930, 8, 1), 'sex': 'M', 'created_at': datetime.datetime(2021, 3, 30, 9, 50, 38, 662702, tzinfo=datetime.timezone.utc), 'deleted_at': None, 'updated_at': datetime.datetime(2021, 4, 12, 16, 55, 42, 865377, tzinfo=datetime.timezone.utc), 'is_test': False}
[2021-07-01 14:26:02,804] {xcom.py:228} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your airflow config.
[2021-07-01 14:26:02,805] {taskinstance.py:1481} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1137, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1311, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1344, in _execute_task
    self.xcom_push(key=XCOM_RETURN_KEY, value=result)
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1919, in xcom_push
    XCom.set(
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/models/xcom.py", line 79, in set
    value = XCom.serialize_value(value)
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/models/xcom.py", line 226, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/lib/python3.8/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/lib/python3.8/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type date is not JSON serializable
[2021-07-01 14:26:02,809] {taskinstance.py:1524} INFO - Marking task as FAILED. dag_id=get_data_patient, task_id=get_users, execution_date=20210701T142403, start_date=20210701T142602, end_date=20210701T142602
[2021-07-01 14:26:02,879] {local_task_job.py:151} INFO - Task exited with return code 1
